{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train an RBM to approximate a quantum state\n",
    "With RBM as a state ansatz, we need to train its parameters in order to make it close to the ground state wave function of a hamiltonian.\n",
    "\n",
    "Notice that the cost function now is energy rather than a known dataset, we use Markov chain Monte Carlo (MCMC) method to extract the energy expectation value and gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "import torch, time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from rbm_torch import RBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A model is a problem definiton, it contains state ansatz, hamiltonian, optimizer and computation graphs for wave function and gradient. Training a model using gradients requires expectation values for at least three operators, $H$, $\\frac{\\partial}{\\partial \\Theta}$ and $H\\frac{\\partial}{\\partial \\Theta}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(model, learning_rate, use_cuda):\n",
    "    '''\n",
    "    train a model.\n",
    "\n",
    "    Args:\n",
    "        model (obj): a model that meet VMC model definition.\n",
    "        learning_rate (float): the learning rate for SGD.\n",
    "    '''\n",
    "    initial_config = np.array([-1, 1] * (model.ansatz.num_visible // 2))\n",
    "    if use_cuda:\n",
    "        model.ansatz.cuda()\n",
    "\n",
    "    while True:\n",
    "        # get expectation values for energy, gradient and their product,\n",
    "        # as well as the precision of energy.\n",
    "        energy, grad, energy_grad, precision = vmc_measure(\n",
    "            model, initial_config=initial_config, num_sample=500)\n",
    "\n",
    "        # update variables using steepest gradient descent\n",
    "        g_list = [eg - energy * g for eg, g in zip(energy_grad, grad)]\n",
    "        for var, g in zip(model.ansatz.parameters(), g_list):\n",
    "            delta = learning_rate * g\n",
    "            var.data -= delta\n",
    "        yield energy, precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above required expectation values can be approximated by emsemble average of following operators over generated samples in VMC run, $\\langle E_{\\rm loc}\\rangle$, $\\langle\\Delta_{\\rm loc}\\rangle$ and $\\langle E_{\\rm loc}\\Delta_{\\rm loc}\\rangle$, with $E_{\\rm loc}=\\frac{\\langle\\psi|H|\\sigma\\rangle}{\\langle\\sigma|\\psi\\rangle}$ and $\\Delta_{\\rm loc}=\\frac{\\partial\\log\\langle\\sigma|\\psi\\rangle}{\\partial \\Theta}$.\n",
    "\n",
    "VMC requires a model with following property\n",
    "* can propose a new configuration, given old configuration.\n",
    "* can give the wave function amplitude on a spin configuration $\\langle\\sigma|\\psi\\rangle$.\n",
    "* given configuration, being able to provide local quantities $E_{\\rm loc}$ and $\\Delta_{\\rm loc}$.\n",
    "\n",
    "As a result, VMC measurements give us desired expectation values and and error estimation for energy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vmc_measure(model, initial_config, num_bath=200, num_sample=1000, num_bin=50, measure_step=None):\n",
    "    '''\n",
    "    Measure an operator.\n",
    "\n",
    "    Args:\n",
    "        model (Model): model definition, requiring the following methods:\n",
    "            * local_measure, get local energy and local gradient.\n",
    "            * prob, get the probability of specific distribution.\n",
    "\n",
    "        num_sample (int): number of samples.\n",
    "\n",
    "    Return:\n",
    "        number,\n",
    "    '''\n",
    "    if measure_step is None:\n",
    "        measure_step = len(initial_config)\n",
    "    print_step = num_sample * measure_step // 5\n",
    "\n",
    "    energy_loc_list, grad_loc_list = [], []\n",
    "    config = initial_config\n",
    "    prob = model.prob(config)\n",
    "\n",
    "    n_accepted = 0\n",
    "    for i in range(num_bath + num_sample * measure_step):\n",
    "        # generate new config and calculate probability ratio\n",
    "        config_proposed = model.propose_config(config)\n",
    "        prob_proposed = model.prob(config_proposed)\n",
    "\n",
    "        # accept/reject a move by metropolis algorithm (world's most famous single line algorithm)\n",
    "        if np.random.random() < prob_proposed / prob:\n",
    "            config = config_proposed\n",
    "            prob = prob_proposed\n",
    "            n_accepted += 1\n",
    "\n",
    "        # measurements\n",
    "        if i >= num_bath and i % measure_step == 0:\n",
    "            # here, I choose a lazy way that re-compute on this config, in order to get its gradients easily.\n",
    "            energy_loc, grad_loc = model.local_measure(config)\n",
    "            energy_loc_list.append(energy_loc)\n",
    "            grad_loc_list.append(grad_loc)\n",
    "\n",
    "        # print statistics\n",
    "        if i % print_step == print_step - 1:\n",
    "            print('%-10s Accept rate: %.3f' %\n",
    "                  (i + 1, n_accepted * 1. / print_step))\n",
    "            n_accepted = 0\n",
    "\n",
    "    # binning statistics\n",
    "    energy_loc_list = np.array(energy_loc_list)\n",
    "    energy, energy_precision = binning_statistics(energy_loc_list, num_bin=num_bin)\n",
    "\n",
    "    # get sample expectations\n",
    "    grad_mean = []\n",
    "    energy_grad = []\n",
    "    for grad_loc in zip(*grad_loc_list):\n",
    "        grad_loc = np.array(grad_loc)\n",
    "        grad_mean.append(grad_loc.mean(axis=0))\n",
    "        energy_grad.append(\n",
    "            (energy_loc_list[(slice(None),) + (None,) * (grad_loc.ndim - 1)] * grad_loc).mean(axis=0))\n",
    "    return energy, grad_mean, energy_grad, energy_precision\n",
    "\n",
    "\n",
    "def binning_statistics(var_list, num_bin):\n",
    "    '''\n",
    "    binning statistics for variable list.\n",
    "    '''\n",
    "    num_sample = len(var_list)\n",
    "    if num_sample % num_bin != 0:\n",
    "        raise\n",
    "    size_bin = num_sample // num_bin\n",
    "\n",
    "    # mean, variance\n",
    "    mean = np.mean(var_list, axis=0)\n",
    "    variance = np.var(var_list, axis=0)\n",
    "\n",
    "    # binned variance and autocorrelation time.\n",
    "    variance_binned = np.var(\n",
    "        [np.mean(var_list[size_bin * i:size_bin * (i + 1)]) for i in range(num_bin)])\n",
    "    t_auto = 0.5 * size_bin * \\\n",
    "        np.abs(np.mean(variance_binned) / np.mean(variance))\n",
    "    stderr = np.sqrt(variance_binned / num_bin)\n",
    "    print('Binning Statistics: Energy = %.4f +- %.4f, Auto correlation Time = %.4f' %\n",
    "          (mean, stderr, t_auto))\n",
    "    return mean, stderr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model definition. When proposing a new configuration, it has 5% probability to flip all spin, can making VMC sample better in Heisenberg model, proposed configuration satisfies spin conservation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class VMCKernel(object):\n",
    "    '''\n",
    "    variational monte carlo kernel.\n",
    "\n",
    "    Attributes:\n",
    "        energy_loc (func): local energy <\\sigma|H|\\psi>/<\\sigma|\\psi>.\n",
    "        ansatz (Module): torch neural network.\n",
    "    '''\n",
    "    def __init__(self, energy_loc, ansatz):\n",
    "        self.ansatz = ansatz\n",
    "        self.energy_loc = energy_loc\n",
    "\n",
    "    def psi(self, config):\n",
    "        '''\n",
    "        query the wavefunction.\n",
    "\n",
    "        Args:\n",
    "            config (1darray): the bit string as a configuration.\n",
    "\n",
    "        Returns:\n",
    "            Variable: the projection of wave function on config, i.e. <config|psi>.\n",
    "        '''\n",
    "        psi = self.ansatz.prob_visible(torch.from_numpy(config))\n",
    "        return psi\n",
    "\n",
    "    def prob(self, config):\n",
    "        '''\n",
    "        probability of configuration.\n",
    "\n",
    "        Args:\n",
    "            config (1darray): the bit string as a configuration.\n",
    "\n",
    "        Returns:\n",
    "            number: probability |<config|psi>|^2.\n",
    "        '''\n",
    "        return abs(self.psi(config).data[0])**2\n",
    "\n",
    "    def local_measure(self, config):\n",
    "        '''\n",
    "        get local quantities energy_loc, grad_loc.\n",
    "\n",
    "        Args:\n",
    "            config (1darray): the bit string as a configuration.\n",
    "\n",
    "        Returns:\n",
    "            number, list: local energy and local gradients for variables.\n",
    "        '''\n",
    "        psi_loc = self.psi(config)\n",
    "\n",
    "        # get gradients {d/dW}_{loc}\n",
    "        self.ansatz.zero_grad()\n",
    "        psi_loc.backward()\n",
    "        grad_loc = [p.grad.data/psi_loc.data[0] for p in self.ansatz.parameters()]\n",
    "\n",
    "        # E_{loc}\n",
    "        eloc = self.energy_loc(config, lambda x: self.psi(x).data, psi_loc.data)[0]\n",
    "        return eloc, grad_loc\n",
    "\n",
    "    @staticmethod\n",
    "    def propose_config(old_config, prob_flip=0.05):\n",
    "        '''\n",
    "        flip two positions as suggested spin flips.\n",
    "\n",
    "        Args:\n",
    "            old_config (1darray): spin configuration, which is a [-1,1] string.\n",
    "            prob_flip (float): the probability to flip all spins, to make VMC more statble in Heisenberg model.\n",
    "\n",
    "        Returns:\n",
    "            1darray: new spin configuration.\n",
    "        '''\n",
    "        # take ~ 5% probability to flip all spin, can making VMC sample better in Heisenberg model\n",
    "        if np.random.random() < prob_flip:\n",
    "            return -old_config\n",
    "\n",
    "        num_spin = len(old_config)\n",
    "        upmask = old_config == 1\n",
    "        flips = np.random.randint(0, num_spin // 2, 2)\n",
    "        iflip0 = np.where(upmask)[0][flips[0]]\n",
    "        iflip1 = np.where(~upmask)[0][flips[1]]\n",
    "\n",
    "        config = old_config.copy()\n",
    "        config[iflip0] = -1\n",
    "        config[iflip1] = 1\n",
    "        return config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate local energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def heisenberg_loc(config, psi_func, psi_loc, J=1.):\n",
    "    '''\n",
    "    local energy for 1D Periodic Heisenberg chain.\n",
    "\n",
    "    Args:\n",
    "        config (1darray): bit string as spin configuration.\n",
    "        psi_func (func): wave function.\n",
    "        psi_loc (number): wave function projected on configuration <config|psi>.\n",
    "        J (float): coupling strengh.\n",
    "\n",
    "    Returns:\n",
    "        number: local energy.\n",
    "    '''\n",
    "    # get weights and flips after applying hamiltonian \\sum_i w_i|sigma_i> = H|sigma>\n",
    "    nsite = len(config)\n",
    "    wl, flips = [], []\n",
    "    # J*SzSz terms.\n",
    "    nn_par = np.roll(config, -1) * config\n",
    "    wl.append(J / 4. * (nn_par).sum(axis=-1))\n",
    "    flips.append(np.array([], dtype='int64'))\n",
    "\n",
    "    # J*SxSx and J*SySy terms.\n",
    "    mask = nn_par != 1\n",
    "    i = np.where(mask)[0]\n",
    "    j = (i + 1) % nsite\n",
    "    wl += [-J / 2.] * len(i)\n",
    "    flips.extend(zip(i, j))\n",
    "\n",
    "    # calculate local energy <psi|H|sigma>/<psi|sigma>\n",
    "    acc = 0\n",
    "    for wi, flip in zip(wl, flips):\n",
    "        config_i = config.copy()\n",
    "        config_i[list(flip)] *= -1\n",
    "        eng_i = wi * psi_func(config_i) / psi_loc\n",
    "        acc += eng_i\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, defined and run a optimization within a tensorflow session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_demo():\n",
    "    seed = 10086\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    max_iter = 200\n",
    "    num_spin = 8\n",
    "    num_hidden = 16\n",
    "    E_exact = -3.65109341\n",
    "\n",
    "    # visualize the loss history\n",
    "    energy_list, precision_list = [], []\n",
    "    def _update_curve(energy, precision):\n",
    "        energy_list.append(energy)\n",
    "        precision_list.append(precision)\n",
    "        plt.errorbar(np.arange(1, len(energy_list) + 1), energy_list, yerr=precision_list, capsize=3)\n",
    "        plt.axhline(E_exact, ls='--')\n",
    "        plt.show()\n",
    "\n",
    "    rbm = RBM(num_spin, num_hidden)\n",
    "    #from random_ansatz import ModifiedBetheAnsatz\n",
    "    #rbm = ModifiedBetheAnsatz(num_spin, 20, num_hidden)\n",
    "    model = VMCKernel(heisenberg_loc, ansatz=rbm)\n",
    "\n",
    "    t0 = time.time()\n",
    "    for i, (energy, precision) in enumerate(train(model, learning_rate = 0.05, use_cuda = False)):\n",
    "        t1 = time.time()\n",
    "        print('Step %d, dE/|E| = %.4f, elapse = %.4f' % (i, -(energy - E_exact)/E_exact, t1-t0))\n",
    "        _update_curve(energy, precision)\n",
    "        t0 = time.time()\n",
    "\n",
    "        # stop condition\n",
    "        if i >= max_iter:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "run_demo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
