{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u0Bp-Metx3XM"
   },
   "source": [
    "# Restricted Boltzmann Machine as a Generative Model\n",
    "The following code is partly referenced from\n",
    "https://github.com/odie2630463/Restricted-Boltzmann-Machines-in-pytorch\n",
    "## Setup PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 363,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "collapsed": true,
    "executionInfo": {
     "elapsed": 794,
     "status": "error",
     "timestamp": 1518075526513,
     "user": {
      "displayName": "刘金国",
      "photoUrl": "//lh3.googleusercontent.com/-lDAT81T3HSE/AAAAAAAAAAI/AAAAAAAAAgw/eH3JEob7M1Y/s50-c-k-no/photo.jpg",
      "userId": "116824001998056121289"
     },
     "user_tz": -480
    },
    "id": "AVQfrTWR-43O",
    "outputId": "181b3298-e93e-4f4b-8dc4-a9fe59273598"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import torch\n",
    "except:\n",
    "    !pip install http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl \n",
    "    !pip install torchvision\n",
    "    import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "99w9A3nOfcVI"
   },
   "source": [
    "### make sure we are using GPU (Nvidia K80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 140,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 830,
     "status": "ok",
     "timestamp": 1518024831141,
     "user": {
      "displayName": "刘金国",
      "photoUrl": "//lh3.googleusercontent.com/-lDAT81T3HSE/AAAAAAAAAAI/AAAAAAAAAgw/eH3JEob7M1Y/s50-c-k-no/photo.jpg",
      "userId": "116824001998056121289"
     },
     "user_tz": -480
    },
    "id": "L6uY7QZV_QHh",
    "outputId": "46a1ffb3-8d20-4396-ebd0-a2fc08493056"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA device 0!\n",
      "\n",
      " 1\n",
      " 2\n",
      " 3\n",
      "[torch.cuda.FloatTensor of size 3 (GPU 0)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "has_cuda = torch.cuda.is_available()\n",
    "if not has_cuda:\n",
    "    print('Not Using CUDA!')\n",
    "else:\n",
    "    print('Using CUDA device %d!'%torch.cuda.current_device())\n",
    "    ts = torch.Tensor([1,2,3])\n",
    "    ts = ts.cuda()\n",
    "    # you will see the location information of a tensor by printing it out.\n",
    "    print(ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sn9DboRcfkuf"
   },
   "source": [
    "## Code an RBM\n",
    "#### Derivative of Negative log-likelihood\n",
    "$\\frac{\\partial{\\mathcal{L}}}{\\partial \\theta}=\\langle \\frac{\\partial E_\\theta(x)}{\\partial \\theta}\\rangle_{x\\sim\\mathcal{D}}-\\langle \\frac{\\partial E_\\theta(x)}{\\partial \\theta}\\rangle_{x\\sim p_{\\theta}(x)}$\n",
    "\n",
    "#### Free energy\n",
    "$E_\\theta(v) = -\\log(p_\\theta(x))$\n",
    "\n",
    "#### $k$-th order Contractive divergence (CD-$k$)\n",
    "Foward Gibbs sampling $x_0\\rightarrow h_0$ + backward Gibbs sampling $h_0\\rightarrow x_1$ + $\\ldots$ + backward Gibbs sampling $h_{k-1}\\rightarrow x_k$.\n",
    "\n",
    "For $k=\\infty$, we will get exact $p_{\\rm \\theta}(x)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "JcDupOzQ_ec6"
   },
   "outputs": [],
   "source": [
    "class RBM(nn.Module):\n",
    "    '''\n",
    "    Restricted Boltzmann Machine\n",
    "\n",
    "    Args:\n",
    "        num_visible (int): number of visible nodes.\n",
    "        num_hidden (int): number of hidden nodes.\n",
    "\n",
    "    Attributes:\n",
    "        W (2darray): weights.\n",
    "        v_bias (1darray): bias for visible layer.\n",
    "        h_bias (1darray): bias for hidden layer.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, num_visible, num_hidden):\n",
    "        super(RBM, self).__init__()\n",
    "        self.W = nn.Parameter(torch.randn(num_hidden, num_visible) * 1e-2)\n",
    "        self.v_bias = nn.Parameter(torch.zeros(num_visible))\n",
    "        self.h_bias = nn.Parameter(torch.randn(num_hidden) * 1e-2)\n",
    "        self.num_visible = num_visible\n",
    "        self.num_hidden = num_hidden\n",
    "\n",
    "    def _v_to_h(self, v):\n",
    "        '''\n",
    "        forward pass p(h|v) from visible to hidden, v is visible input.\n",
    "        '''\n",
    "        p_h = F.sigmoid(F.linear(v, self.W, self.h_bias))\n",
    "        return p_h\n",
    "\n",
    "    def _h_to_v(self, h):\n",
    "        '''\n",
    "        backward pass p(v|h) from hidden to visible, h is hidden input.\n",
    "        '''\n",
    "        p_v = F.sigmoid(F.linear(h, self.W.t(), self.v_bias))\n",
    "        return p_v\n",
    "\n",
    "    def contrastive_divergence(self, v, k):\n",
    "        '''\n",
    "        Args:\n",
    "            v (ndarray): visible input.\n",
    "            k (in): CD-k, means k times v->h & h->v sweep in a single contrastive divergence run.\n",
    "\n",
    "        Returns:\n",
    "            ndarray: visible obtained through CD sampling.\n",
    "        '''\n",
    "        prob_h = self._v_to_h(v)\n",
    "        h = sample_from_prob(prob_h)\n",
    "        for _ in range(k):\n",
    "            prob_v = self._h_to_v(h)\n",
    "            v = sample_from_prob(prob_v)\n",
    "            prob_h = self._v_to_h(v)\n",
    "            h = sample_from_prob(prob_h)\n",
    "        return v\n",
    "\n",
    "    def free_energy(self, v):\n",
    "        '''\n",
    "        free energy E(x) = -log(\\sum_h exp(x, h)) = -log(p(x)*Z).\n",
    "        It can be used to obtain negative log-likelihood L = <E(x)>_{data} - <E(x)>_{model}.\n",
    "\n",
    "        Args:\n",
    "            v (1darray,2darray): visible input with size ([batch_size, ]data_size).\n",
    "\n",
    "        Return:\n",
    "            float: the free energy loss.\n",
    "        '''\n",
    "        vbias_term = v.mv(self.v_bias)\n",
    "        wx_b = F.linear(v, self.W, self.h_bias)\n",
    "        hidden_term = wx_b.exp().add(1).log().sum(dim=-1)\n",
    "        return (-hidden_term - vbias_term).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "LEVdcofVU7Wx"
   },
   "outputs": [],
   "source": [
    "def sample_from_prob(prob_list):\n",
    "    '''\n",
    "    from probability to 0-1 sample.\n",
    "\n",
    "    Args:\n",
    "        prob_list (1darray): probability of being 1.\n",
    "\n",
    "    Returns:\n",
    "        1darray: 0-1 array.\n",
    "    '''\n",
    "    rand = Variable(torch.rand(prob_list.size()))\n",
    "    if prob_list.is_cuda:\n",
    "        rand = rand.cuda()\n",
    "    return (1+torch.sign(prob_list - rand))/2.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6KHy9kQCfqvf"
   },
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "JugGWtAqVLfJ"
   },
   "outputs": [],
   "source": [
    "def mnist01_loader(is_train, use_cuda, batch_size):\n",
    "    '''\n",
    "    yield image and label from mnist dataset.\n",
    "\n",
    "    Args:\n",
    "        is_train (bool): yield traning set if True, else test set.\n",
    "        use_cuda (bool): return data on GPU in True.\n",
    "        batch_size (int): size of a batch.\n",
    "\n",
    "    Returns:\n",
    "        func: an iterator function.\n",
    "    '''\n",
    "    from torchvision import datasets, transforms\n",
    "    import torch.utils.data\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('data', train=is_train,\n",
    "                    download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor()\n",
    "                       ])), batch_size=batch_size, pin_memory=True)\n",
    "\n",
    "    def iterator():\n",
    "        for data, label in test_loader:\n",
    "            # transform to binary mnist image\n",
    "            data = Variable(data.view(-1, 784))\n",
    "            data = data.bernoulli()\n",
    "            if use_cuda:\n",
    "                # copy data to gpu memory\n",
    "                data = data.cuda()\n",
    "                label = label.cuda()\n",
    "            yield data, label\n",
    "    return iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 489,
     "output_extras": [
      {
       "item_id": 3
      },
      {
       "item_id": 4
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 60201,
     "status": "ok",
     "timestamp": 1517852782254,
     "user": {
      "displayName": "刘金国",
      "photoUrl": "//lh3.googleusercontent.com/-lDAT81T3HSE/AAAAAAAAAAI/AAAAAAAAAgw/eH3JEob7M1Y/s50-c-k-no/photo.jpg",
      "userId": "116824001998056121289"
     },
     "user_tz": -480
    },
    "id": "1R8AUsRIVOia",
    "outputId": "06029ef0-3534-4a6e-e2e4-b2a8d579b32d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 784]) torch.Size([64])\n",
      "A hand written digit with label \"5\"\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAA+1JREFUeJzt3cFtU0EUQFEcpQqqoAlEBVRJBYgm\nqIIy+Fmz4DvS+Hsmc8/ZJpYdRVdv8f6Mb8dxfAJ6XmZ/AGAO8UOU+CFK/BAlfogSP0SJH6LED1Hi\nh6jXZ77Z15fvHieEi/36++P2nt8z+SFK/BAlfogSP0SJH6LED1HihyjxQ5T4IUr8ECV+iBI/RIkf\nosQPUeKHKPFDlPghSvwQJX6IEj9EiR+ixA9R4oco8UOU+CFK/BAlfogSP0SJH6LED1HihyjxQ5T4\nIUr8ECV+iBI/RIkfosQPUa+zPwD8z88/v09//u3zl6HXj7j33h+ByQ9R4oco8UOU+CFK/BAlfogS\nP0TZ82/uyl33bDv/bc9g8kOU+CFK/BAlfogSP0SJH6Ks+h7Ayukao0d2R47dFv6nJj9EiR+ixA9R\n4oco8UOU+CFK/BBlz/8AM6+QLrvy+uwdrua+x+SHKPFDlPghSvwQJX6IEj9EiR+i7Pmf4Opz6St/\nFbVnHNZl8kOU+CFK/BAlfogSP0SJH6LED1H2/AsY3aWfvX72nr1wLv6jMvkhSvwQJX6IEj9EiR+i\nxA9R4ocoe/4NzN7l8zGZ/BAlfogSP0SJH6LED1Hihyirvg2sfKSXdZn8ECV+iBI/RIkfosQPUeKH\nKPFDlD0/p0afE3B197pMfogSP0SJH6LED1HihyjxQ5T4Icqef3Oje/bRPf/Z6z0DMJfJD1Hihyjx\nQ5T4IUr8ECV+iBI/RNnzc+reLn7kOYCrv1PAcwTnTH6IEj9EiR+ixA9R4oco8UOU+CHKnp8hI7v0\nq/f8nDP5IUr8ECV+iBI/RIkfosQPUeKHKPFDlPghSvwQJX6IEj9EiR+ixA9RjvQy5N6x3Cuvz3Y1\n9xiTH6LED1HihyjxQ5T4IUr8ECV+iLLnj7v6+mzXc6/L5Ico8UOU+CFK/BAlfogSP0SJH6Ls+Te3\n8p7defy5TH6IEj9EiR+ixA9R4oco8UOUVd8CRq+/Xnmdx7pMfogSP0SJH6LED1HihyjxQ5T4Icqe\n/wF2vv7asdt9mfwQJX6IEj9EiR+ixA9R4oco8UOUPf877Xpm3h6/y+SHKPFDlPghSvwQJX6IEj9E\niR+iMnv+lff0du3MYPJDlPghSvwQJX6IEj9EiR+ixA9RmT2/XTr8y+SHKPFDlPghSvwQJX6IEj9E\niR+ixA9R4oco8UOU+CFK/BAlfogSP0SJH6LED1HihyjxQ5T4IUr8ECV+iBI/RN2O45j9GYAJTH6I\nEj9EiR+ixA9R4oco8UOU+CFK/BAlfogSP0SJH6LED1HihyjxQ5T4IUr8ECV+iBI/RIkfosQPUeKH\nKPFDlPgh6g1HyGT5TlDlZgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x14c85c060550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "loader = mnist01_loader(is_train=True, use_cuda=False, batch_size=64)\n",
    "# let's check the data and labels\n",
    "for data, label in loader():\n",
    "    print(data.shape, label.shape)\n",
    "    print('A hand written digit with label \"%d\"'%label[0])\n",
    "    plt.imshow(data[0].data.numpy().reshape([28, 28]))\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U0gdtiqt34_k"
   },
   "source": [
    "## Use RBM as a Generative Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 369,
     "output_extras": [
      {
       "item_id": 19
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 422996,
     "status": "ok",
     "timestamp": 1517853205415,
     "user": {
      "displayName": "刘金国",
      "photoUrl": "//lh3.googleusercontent.com/-lDAT81T3HSE/AAAAAAAAAAI/AAAAAAAAAgw/eH3JEob7M1Y/s50-c-k-no/photo.jpg",
      "userId": "116824001998056121289"
     },
     "user_tz": -480
    },
    "id": "gXQOWrPYVUrS",
    "outputId": "7925342c-4ac4-4cf4-f9f1-c6c754112f02"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, Mean \"Loss\" = -0.6259, Elapse = 22.7901\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-b0fc8321ddb9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m# calculate the \"loss\", the last node in computation graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mv1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrastive_divergence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfree_energy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mrbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfree_energy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mloss_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-4a2c2d77bd86>\u001b[0m in \u001b[0;36mcontrastive_divergence\u001b[0;34m(self, v, k)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mprob_v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_h_to_v\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_from_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprob_v\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m             \u001b[0mprob_h\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_v_to_h\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_from_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprob_h\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-4708c5edbb4e>\u001b[0m in \u001b[0;36msample_from_prob\u001b[0;34m(prob_list)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mrand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprob_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mprob_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_cuda\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mrand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrand\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprob_list\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mrand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/leo/anaconda3/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device, async)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masync\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mCudaTransfer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/leo/anaconda3/lib/python3.6/site-packages/torch/autograd/_functions/tensor.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, i, device, async)\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masync\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masync\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/leo/anaconda3/lib/python3.6/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36m_cuda\u001b[0;34m(self, device, async)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mnew_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnew_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "use_cuda = True\n",
    "num_visible = 784\n",
    "num_hidden = 500\n",
    "\n",
    "# set seed for pytorch-cpu, pytorch-gpu and numpy\n",
    "seed = 10086\n",
    "torch.manual_seed(seed)\n",
    "if use_cuda: torch.cuda.manual_seed_all(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "# define network and dataset, and transfer model data into GPU memory\n",
    "rbm = RBM(num_visible, num_hidden)\n",
    "if use_cuda: rbm = rbm.cuda()\n",
    "loader = mnist01_loader(True, use_cuda, batch_size=64)\n",
    "\n",
    "# with the stochastic gradient descent optimizer,\n",
    "# we optimize model parameters with learning rate 0.1.\n",
    "train_op = torch.optim.SGD(rbm.parameters(), 0.1)\n",
    "for epoch in range(10):\n",
    "    t0 = time.time()\n",
    "    loss_list = []\n",
    "    for data, label in loader():\n",
    "        # calculate the \"loss\", the last node in computation graph\n",
    "        v1 = rbm.contrastive_divergence(data, k=10)\n",
    "        loss = rbm.free_energy(data) - rbm.free_energy(v1)\n",
    "        loss_list.append(loss.data[0])\n",
    "\n",
    "        # get gradients using back propagation.\n",
    "        # zero_grad are needed before backward, otherwise gradients are accumulated.\n",
    "        train_op.zero_grad()\n",
    "        loss.backward()\n",
    "        # update parameters using gradients using gradients.\n",
    "        train_op.step()\n",
    "    t1 = time.time()\n",
    "    print('epoch %d, Mean \"Loss\" = %.4f, Elapse = %.4f'%(epoch, np.mean(loss_list), t1-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 270,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1021,
     "status": "ok",
     "timestamp": 1517853206523,
     "user": {
      "displayName": "刘金国",
      "photoUrl": "//lh3.googleusercontent.com/-lDAT81T3HSE/AAAAAAAAAAI/AAAAAAAAAgw/eH3JEob7M1Y/s50-c-k-no/photo.jpg",
      "userId": "116824001998056121289"
     },
     "user_tz": -480
    },
    "id": "XDweacKvVzhE",
    "outputId": "16c5ec5e-4a72-44c7-afd4-b9527965791c"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAO8AAAD8CAYAAACfMvOMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n+Q+Stm0C9uXCxwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x14c84cfcfd68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "# check for CD-1 generated data, they are similar to original data\n",
    "data, label = next(mnist01_loader(False, use_cuda, batch_size=32)())\n",
    "generated = rbm.contrastive_divergence(data, k=1)\n",
    "\n",
    "gs = plt.GridSpec(2,1)\n",
    "for irow, img in [(0, data), (1, generated)]:\n",
    "    img_grid = make_grid(img.view(32, 1, 28, 28).data)\n",
    "    npimg = np.transpose(img_grid.cpu().numpy(), (1, 2, 0))\n",
    "\n",
    "    plt.subplot(gs[irow,0])\n",
    "    plt.imshow(npimg)\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fGVr6K_Y3ixs"
   },
   "source": [
    "## Quiz\n",
    "* Try to explain why the loss goes up.\n",
    "* How much a GPU can accelerate in this case? Answer should be $\\frac{t_{\\rm CPU}}{t_{\\rm GPU}}$.\n",
    "* Try CD-10 training, and CD-10 reconstruction, tell the difference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "daD390CW2NKH"
   },
   "source": [
    "## Task\n",
    "To see how RBM can be useful, try to solve the following problem.\n",
    "\n",
    "Top half of an image is lost, the only knowlege we know is it is a hand written number, try to recover this image.\n",
    "\n",
    "This image is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 266,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2348,
     "status": "ok",
     "timestamp": 1517853209395,
     "user": {
      "displayName": "刘金国",
      "photoUrl": "//lh3.googleusercontent.com/-lDAT81T3HSE/AAAAAAAAAAI/AAAAAAAAAgw/eH3JEob7M1Y/s50-c-k-no/photo.jpg",
      "userId": "116824001998056121289"
     },
     "user_tz": -480
    },
    "id": "JGHW_08wc7Lb",
    "outputId": "5cfb95d5-0fda-4190-f37d-951cc760e179"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAADD5JREFUeJzt3XuU13Mex/HPdJlqmrbpMmiaNFFs\nUumUXCNtLkW1dpE0OO5JmHNIWxsNx2LCtHZZ6ViLyNLiEN1mrW4iprRWlyFdZirddDWXpmZm/7D8\n93lNh+1XeT0f/758+v0a8+r7x/v7+XySampqAgA/dQ71FwBwaFB+wBTlB0xRfsAU5QdMUX7AFOUH\nTFF+wBTlB0zVS+SHTV3VXb5OOP7BoXJ9442V0axP/gdy7XubT5R5g9FNZL5+TPyr921bJNeu2pMu\n82Ur28j8X/3yZd7vhZHR7LpL/ynXjmrxpcxnljWQ+ZPr+8i85K120Szvtr/KtXcUDpb50I6FMm/f\ncHM0y108QK6965QCmafVLZP5A5OHyDz3mpej2ZSvT5dry/fXl3nBeROS5H/wPzz5AVOUHzBF+QFT\nlB8wRfkBU5QfMEX5AVMJnfPf8+5VMm/0690y79J6bTTrm7pMrp3xYG+Zr7tGn2iUe9Lr0ezRFRfI\ntRe1XSHzot1ZMu9TkCPz+mLse3Zj/Q5Cu7eHybzjY1tlnlStf257xlVEswnZeo4ff0PgOz1eWi3z\nu1+8PprV76J/16Zv7SzzqmuTZT51zuMyz8m+NZp9c3IjubY6uZYx/nk6/h5PfsAU5QdMUX7AFOUH\nTFF+wBTlB0xRfsBUQuf8Jz70lcwHzl0u87fPOiGa5ZadKde+tUrPXbPb633px/TfFc3qzEuTay+/\n42OZjxmizyLo9clNMv+8/7PR7MLMU+XaOvn63/9N+XqeXTO7hcyPzyyJZnmv/EOuXVaZIfPOydtk\nXtE2fv7DcU/rcwpSH9gr83U9s2SeWUuzyjIaRrP77pos1046tbv+w/+o4+/x5AdMUX7AFOUHTFF+\nwBTlB0xRfsBUQkd9oWmqjAc30cdIv9khPo7bdq8ezWRfeovMQ/UXMp6zp2M0233SPrl25O23yfy5\np/TR3AU9npH5BZePiGZl0/XW1dvbzJT5U+/0k3m95jIOv8uaHs2uWnyDXDvg+M9lPm9XfPQbQghN\nlsXHlJ3H6/Hrypv1Ue+b9Cnz4YrMM2S+cWJ1NMu7L1uu3TJOf/aB4skPmKL8gCnKD5ii/IApyg+Y\novyAKcoPmEronL/Os/FjnEMI4Tc33iHzxuM3RLMmeZly7U1TXpV5/lh9rPjCsVXRLC1LX5l8zaNv\nyPyKh+JXbIcQwvYe+2XecXN8a+v2Ba3k2llP6OvB2x8f38ocQgibztTbmaft7BbNzshcK9cu26W/\n+2XHLJb5mkXxWf3cip5y7ehX4ldohxDCpY23y3zguN4yb/dGfM5fp1L//06q1tusDxRPfsAU5QdM\nUX7AFOUHTFF+wBTlB0xRfsBUUk2NvmL5/6nDw/nyw/an6O9SrzR+NXFta7Pe1Xvu947cIfMNq1tG\nszaz5dKQOn+VzC+er88xKCo7Rual++PHUM+bo6+abqo/Osy5f4LMd1brmfSiivjx25NKzpFrd0zW\n7yDcOfo1mf9t2KBolpobf2ckhBA2lTaRefOr9Zw/t3CWzId8cHM0W9L7L3ptH73ff+bKR2q5w/s7\nPPkBU5QfMEX5AVOUHzBF+QFTlB8wRfkBUwmd8/f51cPyw6rGfCPXd20en83O33icXJueq/fcJ31R\nLPPiEfF5+Su36HP3c27U5/bv7KD3Z1c11GPbVgv2RLO6JVvk2uXj2so8c7b+7Mbry2TeddJ/olm7\nBlvl2rx5F8t87Llvy7x1/fi7G1O36avLP5zWReaFt+p7sE+fkCPzzEvWRrP72k6Ta7skx8+WCCGE\n1Ix1zPkBxFF+wBTlB0xRfsAU5QdMUX7AVEKP7v62tR5pbV6XLvOjU+IjrfJF8S23IYSwL2+9zOve\nq0eFWVNKotmQHvqq6YvyPpX58nMayTwpJUXnDeNbervO+Fqu/Wqa/ntv7KVHwZnv6+9eUBI/Pjvt\nT93l2vaj9XdfsKuDzJf8PT6e7TpYX//d7Mv40dohhJC9Wo8h0/vp37ecNgXR7OqP9O9Ts9n6Z174\nnIx/wJMfMEX5AVOUHzBF+QFTlB8wRfkBU5QfMJXQOX9Vst5p2KRlqczbNIpv0VycqufRA1p9JvPZ\nO/UWz+1ntY5m5V/rzx7UbYnMFw4aJvMLRs2X+Yz8+BHYs57Wx1+/PPoJmY/4vb42fe4zk2ReVl0Z\nzc499k65dttqfWT5+vX677a3fXzr6/zP4u8fhBBCalv9XNyx5WiZp01Nlfnja66MZlXD68q1+1IP\naMdurXjyA6YoP2CK8gOmKD9givIDpig/YIryA6YOq6O7K0btlOvrPhnfs5+6VF+5XLNPX9GdlKL3\nSJc+E5+tNrqnlv32pRUyT35Wv99QkaPPKih7JH58dmmlPrK83tQWMm/+un4/4oWV+n7yG1f/Npod\nl7pNrh3ecq7M+792t8wbtd8VzUqLfyHXpi/Ws/TKWmbtna/W5wVsHRZ/byR9ov5d7pSqzzkY3Wk6\nR3cDiKP8gCnKD5ii/IApyg+YovyAKcoPmErofv56C5fJfMdcfY57ylHx1wSKx2XItW/2fVLmj2zs\nJ/PlK+Ln2/eZuFKuLdp5lMz1FD+Ed9+ZLPP+KwdGs01L9J749h9ulvlrRe/J/LRFN8u8/Nv4nQLr\nmjbTa6v0Owpqjh9CCC0ax99/qNqWJtfeM/Ylmef9YajMS3JPkHmzP6+LZismdZJr55+t/+zRevkP\nePIDpig/YIryA6YoP2CK8gOmKD9givIDphI65/8i/xSZ1zSMn/EeQgjp/45vU76t11ty7ZWTc2Re\nr1RvgW6UHM+KZujB6tZT9L+xvQcskPkD2+L3zIcQwtDWH0WzKW/oWfqOHvodhM6zRsg8ZZX4wYQQ\nGotjFNIL5dKwfm26/uxzmsp8Xe/4OQstN+hzLPql6LMG8sv1+r1pulp7h8bff3h5wWNy7eClN8j8\nQPHkB0xRfsAU5QdMUX7AFOUHTFF+wFRCR30NtuirhzMW7Jd5yU3xUWDhnnZybYueeutq02y9PfSb\n/vFtlJXXb5drq3bq65o/veRYmZ88TR/lvLI8vp35q8v0Z1/c9xOZbyzX47TuPYtlnpkc/9mMrxos\n12Z8tEXmzZfqI9NbXLc7mhUXZcm1H+9tKPN65dUyLx6k8+fHvxrNhl97u1ybsVaPIcMAHX+PJz9g\nivIDpig/YIryA6YoP2CK8gOmKD9gKqFXdG/ZkCE/rO+jI+X6Xb+MvwfQq5s+Pnv+cn3c8QlZm2Re\n97L4Ndo3LFos104sOVfm+6v1v8EVz7WS+abz4z+X4T3fl2ufLzpd5uO7vi7zUZ/Fr+AOIYSxnaZH\nsxdP6yLX5hQulPn9Y/TW1qafx98xKB6oD0xP/1RvL+/4oL6Ce00vGYc1Y7pFs9Zz9Wdf9MQcmY86\naSZXdAOIo/yAKcoPmKL8gCnKD5ii/IApyg+YSuic//w6lyfuw3DYm7Vx6U9af2GGPgreVUH1VOb8\nAOIoP2CK8gOmKD9givIDpig/YIryA6YSem4//PzUWT4OHp78gCnKD5ii/IApyg+YovyAKcoPmKL8\ngCnKD5ii/IApyg+YovyAKcoPmKL8gCnKD5hiSy8OWxzNfXDx5AdMUX7AFOUHTFF+wBTlB0xRfsAU\n5QdMMeeHdDCP3maOf2jx5AdMUX7AFOUHTFF+wBTlB0xRfsAU5QdMMeeHVNssniu4j1w8+QFTlB8w\nRfkBU5QfMEX5AVOUHzBF+QFTzPnNHew5PXv2D188+QFTlB8wRfkBU5QfMEX5AVOUHzDFqA8/CaO8\nIxdPfsAU5QdMUX7AFOUHTFF+wBTlB0xRfsAUc/6fOY7WRgxPfsAU5QdMUX7AFOUHTFF+wBTlB0xR\nfsAUc35I7Nf/+eLJD5ii/IApyg+YovyAKcoPmKL8gCnKD5hizv8zwJ59/Bg8+QFTlB8wRfkBU5Qf\nMEX5AVOUHzBF+QFTzPmPAAdzjs9+fV88+QFTlB8wRfkBU5QfMEX5AVOUHzBF+QFTlB8wRfkBU5Qf\nMEX5AVOUHzBF+QFTlB8wxZbeIwDbbnEw8OQHTFF+wBTlB0xRfsAU5QdMUX7AFOUHTCXV1NQc6u8A\n4BDgyQ+YovyAKcoPmKL8gCnKD5ii/IApyg+YovyAKcoPmKL8gCnKD5ii/IApyg+YovyAKcoPmKL8\ngCnKD5ii/IApyg+YovyAKcoPmKL8gCnKD5j6L2TeiCUL8JlxAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x14e1e93e0d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# presented data, npdata[:14] is replace by noises, with rest the correct values.\n",
    "npdata = np.array([0.87207395, 0.30172917, 0.20748128, 0.8095541, 0.6876969, 0.1532767, 0.62968737, 0.7779726, 0.7118719, 0.53654927, 0.94739664, 0.4471923, 0.8174037, 0.99884754, 0.88779926, 0.71121424, 0.3754819, 0.8892206, 0.6074483, 0.80546534, 0.86275977, 0.59773445, 0.8402653, 0.86507905, 0.42217958, 0.87019306, 0.7207597, 0.70173293, 0.5013676, 0.632447, 0.7610868, 0.9116219, 0.27281326, 0.5140466, 0.85905105, 0.6330603, 0.7861834, 0.48230517, 0.5583505, 0.46642596, 0.9083495, 0.5351944, 0.1025035, 0.098153934, 0.5750544, 0.16645348, 0.16748504, 0.88547695, 0.43294504, 0.6214652, 0.71871835, 0.091364935, 0.93197143, 0.18161148, 0.34041223, 0.36640248, 0.05945792, 0.84343576, 0.05011359, 0.020642783, 0.96630734, 0.02089095, 0.8930233, 0.3763136, 0.9165772, 0.97183466, 0.63145226, 0.9990819, 0.009387237, 0.50575066, 0.64946336, 0.35694385, 0.69572824, 0.9233393, 0.86297685, 0.95064604, 0.5617286, 0.20560175, 0.7403321, 0.27093577, 0.97413605, 0.26959816, 0.87772864, 0.044952888, 0.102199115, 0.9718467, 0.16127962, 0.655842, 0.15577097, 0.019478982, 0.79594487, 0.5539078, 0.23640345, 0.9437329, 0.9587844, 0.17794718, 0.6766039, 0.8290011, 0.4769842, 0.4305203, 0.8977303, 0.6218739, 0.7924648, 0.76474386, 0.3790167, 0.77901715, 0.14843856, 0.49938354, 0.0016661843, 0.53694785, 0.28133965, 0.50130546, 0.7144231, 0.21561551, 0.71205837, 0.22371855, 0.87220854, 0.26955116, 0.23340793, 0.35401136, 0.8505834, 0.3398249, 0.5540171, 0.10345899, 0.42512947, 0.038393788, 0.14067493, 0.35083002, 0.78112274, 0.7566516, 0.7144876, 0.85403043, 0.17873417, 0.35017425, 0.8706891, 0.9905999, 0.03664582, 0.21388373, 0.19397263, 0.49474058, 0.45710087, 0.5013515, 0.45443046, 0.49812528, 0.20585743, 0.6777932, 0.52848434, 0.24695043, 0.05329345, 0.8382803, 0.7743761, 0.75724375, 0.47649342, 0.3232994, 0.97870475, 0.95442826, 0.8724979, 0.7017745, 0.31166396, 0.86247295, 0.19751902, 0.7225639, 0.66581416, 0.053260047, 0.91416854, 0.5880709, 0.97473216, 0.11180539, 0.19542904, 0.6878177, 0.77867174, 0.6552874, 0.15082805, 0.036130577, 0.40634972, 0.92630273, 0.20962614, 0.34388322, 0.37616885, 0.15954784, 0.06997797, 0.53446907, 0.2530169, 0.15803383, 0.79036176, 0.84305835, 0.54108804, 0.8501002, 0.8879858, 0.75407153, 0.42112336, 0.9809118, 0.38506842, 0.70881325, 0.9115492, 0.98289156, 0.29546624, 0.5558135, 0.73718935, 0.4230012, 0.6937958, 0.16916722, 0.08621408, 0.6282674, 0.78306913, 0.032396235, 0.05875099, 0.08453581, 0.7941298, 0.44791576, 0.49781203, 0.24143413, 0.6512627, 0.20860681, 0.697907, 0.7528845, 0.372322, 0.7488793, 0.27171475, 0.72370976, 0.69339174, 0.8918535, 0.5999, 0.30938724, 0.3181647, 0.64025414, 0.78654414, 0.47598284, 0.8310249, 0.11720193, 0.2878025, 0.52041465, 0.9025964, 0.28781494, 0.8044487, 0.3056101, 0.33250284, 0.92022175, 0.286686, 0.9976094, 0.9832922, 0.31882682, 0.55324644, 0.43472946, 0.5232928, 0.54625267, 0.3906454, 0.62188476, 0.27731606, 0.16046757, 0.5718505, 0.35741845, 0.19788711, 0.6796674, 0.23651811, 0.08174702, 0.06336878, 0.09723609, 0.6873774, 0.14071466, 0.10673229, 0.72016853, 0.14792068, 0.6807766, 0.65582806, 0.30159968, 0.033888057, 0.9616834, 0.71672386, 0.7785365, 0.93777555, 0.4879574, 0.6355177, 0.5111196, 0.3009759, 0.3500596, 0.74764377, 0.13936538, 0.7483063, 0.81750077, 0.022937937, 0.4070562, 0.31818643, 0.5540159, 0.92213124, 0.73755354, 0.5571023, 0.75489575, 0.67721623, 0.72045094, 0.9948514, 0.70227563, 0.4672006, 0.106317885, 0.9804078, 0.6265774, 0.5751128, 0.6412867, 0.7626526, 0.63349885, 0.6859269, 0.42727026, 0.87387127, 0.30769062, 0.21811083, 0.7262418, 0.3143378, 0.5617967, 0.52690506, 0.5614177, 0.2285414, 0.85394025, 0.4490645, 0.3991946, 0.4290848, 0.260644, 0.45061842, 0.79720527, 0.8023241, 0.8577737, 0.15940316, 0.28310093, 0.5588658, 0.40793347, 0.3871484, 0.19407174, 0.090147026, 0.3032796, 0.56522983, 0.31781578, 0.9819852, 0.27190876, 0.27358428, 0.08329663, 0.9401394, 0.64813715, 0.43394515, 0.20502856, 0.6062421, 0.77016854, 0.6724567, 0.05586233, 0.30247933, 0.6605889, 0.59062487, 0.07923536, 0.79024094, 0.7947558, 0.47801945, 0.7789812, 0.7338063, 0.81782705, 0.86098266, 0.37724164, 0.025790595, 0.13603827, 0.70920366, 0.39994055, 0.9000277, 0.24124062, 0.556982, 0.9389691, 0.19500403, 0.0904483, 0.9657381, 0.36499324, 0.53046125, 0.7467004, 0.558991, 0.70214766, 0.047792256, 0.8731797, 0.6984725, 0.6879274, 0.28380287, 0.5657824, 0.82289946, 0.628091, 0.8842273, 0.6312523, 0.86718184, 0.046136532, 0.89170617, 0.27153188, 0.12342716, 0.4058729, 0.21863484, 0.7674653, 0.026953213, 0.44575384, 0.20404944, 0.8207133, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], dtype='float32').reshape([28, 28])\n",
    "plt.imshow(npdata)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AbrkPDTZCNMK"
   },
   "source": [
    "Here, I will give you some **hint**.\n",
    "\n",
    "* Train a better RBM to complete this task.\n",
    "\n",
    "* Make this image a initial input, and perform Gibbs sampling sounds a good idea. Try to write a modified version of **contrastive_divergence** method.\n",
    "* data transform related API (pytorch API page: http://pytorch.org/docs/0.3.0/): \n",
    "\n",
    "```python\n",
    "    torch.from_numpy\n",
    "    torch.Tensor.numpy\n",
    "    torch.Tensor.cuda\n",
    "    torch.Tensor.cpu\n",
    "    torch.autograd.Variable\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# complete your tasks here"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "rbm_generation_with_solution.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
